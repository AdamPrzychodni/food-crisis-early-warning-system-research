{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading Processed Data ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "------------------------------ \n",
      "\n",
      "--- Step 2: Preparing Data for Aggregation ---\n",
      "Columns in df_clusters (from risk-factors-categories.xlsx):\n",
      "Index(['risk_factor', 'cluster'], dtype='object')\n",
      "\n",
      "Merged risk mentions with thematic clusters.\n",
      "------------------------------ \n",
      "\n",
      "--- Step 3: Aggregating Daily Risk Counts ---\n",
      "Calculated raw daily counts of risk mentions per location and theme.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location_id</th>\n",
       "      <th>location_name_english</th>\n",
       "      <th>cluster</th>\n",
       "      <th>risk_mention_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>sy</td>\n",
       "      <td>syria</td>\n",
       "      <td>humanitarian aid</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>ps_gz</td>\n",
       "      <td>gaza</td>\n",
       "      <td>food crisis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>ps_gz_2</td>\n",
       "      <td>gaza</td>\n",
       "      <td>conflicts and violence</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>ps_gz_2</td>\n",
       "      <td>gaza</td>\n",
       "      <td>food crisis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>ps_gz_5</td>\n",
       "      <td>rafah</td>\n",
       "      <td>food crisis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date location_id location_name_english                 cluster  \\\n",
       "0 2024-06-24          sy                 syria        humanitarian aid   \n",
       "1 2024-06-25       ps_gz                  gaza             food crisis   \n",
       "2 2024-06-25     ps_gz_2                  gaza  conflicts and violence   \n",
       "3 2024-06-25     ps_gz_2                  gaza             food crisis   \n",
       "4 2024-06-25     ps_gz_5                 rafah             food crisis   \n",
       "\n",
       "   risk_mention_count  \n",
       "0                   2  \n",
       "1                   1  \n",
       "2                   2  \n",
       "3                   2  \n",
       "4                   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ \n",
      "\n",
      "--- Step 4: Normalizing Risk Counts ---\n",
      "Normalized risk scores by total daily article volume.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location_id</th>\n",
       "      <th>location_name_english</th>\n",
       "      <th>cluster</th>\n",
       "      <th>risk_mention_count</th>\n",
       "      <th>total_articles_published</th>\n",
       "      <th>normalized_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>sy</td>\n",
       "      <td>syria</td>\n",
       "      <td>humanitarian aid</td>\n",
       "      <td>2</td>\n",
       "      <td>3778</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>ps_gz</td>\n",
       "      <td>gaza</td>\n",
       "      <td>food crisis</td>\n",
       "      <td>1</td>\n",
       "      <td>3847</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>ps_gz_2</td>\n",
       "      <td>gaza</td>\n",
       "      <td>conflicts and violence</td>\n",
       "      <td>2</td>\n",
       "      <td>3847</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>ps_gz_2</td>\n",
       "      <td>gaza</td>\n",
       "      <td>food crisis</td>\n",
       "      <td>2</td>\n",
       "      <td>3847</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>ps_gz_5</td>\n",
       "      <td>rafah</td>\n",
       "      <td>food crisis</td>\n",
       "      <td>1</td>\n",
       "      <td>3847</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date location_id location_name_english                 cluster  \\\n",
       "0 2024-06-24          sy                 syria        humanitarian aid   \n",
       "1 2024-06-25       ps_gz                  gaza             food crisis   \n",
       "2 2024-06-25     ps_gz_2                  gaza  conflicts and violence   \n",
       "3 2024-06-25     ps_gz_2                  gaza             food crisis   \n",
       "4 2024-06-25     ps_gz_5                 rafah             food crisis   \n",
       "\n",
       "   risk_mention_count  total_articles_published  normalized_risk  \n",
       "0                   2                      3778         0.000529  \n",
       "1                   1                      3847         0.000260  \n",
       "2                   2                      3847         0.000520  \n",
       "3                   2                      3847         0.000520  \n",
       "4                   1                      3847         0.000260  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ \n",
      "\n",
      "--- Step 5: Constructing Risk Indices ---\n",
      "Calculated Composite Risk Index (CRI).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location_id</th>\n",
       "      <th>location_name_english</th>\n",
       "      <th>composite_risk_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>sy</td>\n",
       "      <td>syria</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>ps_gz</td>\n",
       "      <td>gaza</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>ps_gz_2</td>\n",
       "      <td>gaza</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>ps_gz_5</td>\n",
       "      <td>rafah</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>sy_hl</td>\n",
       "      <td>aleppo</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date location_id location_name_english  composite_risk_index\n",
       "0 2024-06-24          sy                 syria              0.000529\n",
       "1 2024-06-25       ps_gz                  gaza              0.000260\n",
       "2 2024-06-25     ps_gz_2                  gaza              0.000520\n",
       "3 2024-06-25     ps_gz_5                 rafah              0.000260\n",
       "4 2024-06-25       sy_hl                aleppo              0.000260"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ \n",
      "\n",
      "--- Step 6: Saving Final Index Data ---\n",
      "Final time-series data saved to: ../data/04_feature\n",
      "------------------------------ \n",
      "\n",
      "--- Step 7: Example Visualization ---\n",
      "No data found for location: Baghdad\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 1. Load Necessary Data (Corrected) ---\n",
    "print(\"--- Step 1: Loading Processed Data ---\")\n",
    "DATA_DIR = '../data'\n",
    "MODELS_DIR = os.path.join(DATA_DIR, '03_models')\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, '01_raw')\n",
    "\n",
    "# CORRECTED: Load the file you just created from notebook 05\n",
    "df_final_exploded = pd.read_csv(os.path.join(MODELS_DIR, 'risk_mentions_geotagged_FINAL.csv'))\n",
    "\n",
    "# CORRECTED: Load the risk factor cluster file with the correct name\n",
    "df_clusters = pd.read_excel(os.path.join(RAW_DATA_DIR, 'risk-factors-categories.xlsx'))\n",
    "\n",
    "# This file is needed for normalization\n",
    "df_geo_articles = pd.read_pickle(os.path.join(DATA_DIR, '02_processed', 'news_geographically_filtered.pkl'))\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "print(\"-\" * 30, \"\\n\")\n",
    "\n",
    "# --- 2. Prepare the Data (Corrected) ---\n",
    "print(\"--- Step 2: Preparing Data for Aggregation ---\")\n",
    "\n",
    "# --- HELPFUL DEBUGGING STEP ---\n",
    "# Print the column names to see what they are actually called\n",
    "print(\"Columns in df_clusters (from risk-factors-categories.xlsx):\")\n",
    "print(df_clusters.columns)\n",
    "# -----------------------------\n",
    "\n",
    "# Ensure the 'date' column is in datetime format\n",
    "df_final_exploded['date'] = pd.to_datetime(df_final_exploded['date'])\n",
    "\n",
    "# Merge the risk mentions with their thematic clusters\n",
    "# CORRECTED: Changed 'right_on' to the correct column name. It's likely 'risk_factor'.\n",
    "df_merged = pd.merge(df_final_exploded, df_clusters, on='risk_factor') # Using 'on' is cleaner when column names match\n",
    "\n",
    "print(\"\\nMerged risk mentions with thematic clusters.\")\n",
    "print(\"-\" * 30, \"\\n\")\n",
    "\n",
    "\n",
    "# --- 3. Aggregate Risk Mentions (Corrected) ---\n",
    "print(\"--- Step 3: Aggregating Daily Risk Counts ---\")\n",
    "\n",
    "# CORRECTED: Changed 'theme' to 'cluster' to match the actual column name\n",
    "df_daily_counts = df_merged.groupby([pd.Grouper(key='date', freq='D'), 'location_id', 'location_name_english', 'cluster']).size().reset_index(name='risk_mention_count')\n",
    "\n",
    "print(\"Calculated raw daily counts of risk mentions per location and theme.\")\n",
    "display(df_daily_counts.head())\n",
    "print(\"-\" * 30, \"\\n\")\n",
    "\n",
    "\n",
    "# --- 4. Normalization (Crucial Step) ---\n",
    "# To avoid bias from varying news volume, we normalize by the number of articles published per day.\n",
    "# NOTE: This is a simplified normalization. A more advanced approach would be to get article counts *per location*,\n",
    "# which would require re-running the geotagger on ALL articles, not just those with risks.\n",
    "# For this assessment, normalizing by total daily articles is a reasonable simplification.\n",
    "\n",
    "print(\"--- Step 4: Normalizing Risk Counts ---\")\n",
    "df_geo_articles['date'] = pd.to_datetime(df_geo_articles['date'])\n",
    "daily_article_volume = df_geo_articles.groupby(pd.Grouper(key='date', freq='D')).size().reset_index(name='total_articles_published')\n",
    "\n",
    "# Merge the risk counts with the total article volume for normalization\n",
    "df_normalized = pd.merge(df_daily_counts, daily_article_volume, on='date')\n",
    "df_normalized['normalized_risk'] = df_normalized['risk_mention_count'] / df_normalized['total_articles_published']\n",
    "\n",
    "print(\"Normalized risk scores by total daily article volume.\")\n",
    "display(df_normalized.head())\n",
    "print(\"-\" * 30, \"\\n\")\n",
    "\n",
    "\n",
    "# --- 5. Calculate Thematic and Composite Risk Indices ---\n",
    "print(\"--- Step 5: Constructing Risk Indices ---\")\n",
    "# The 'normalized_risk' is already our Thematic Risk Index for each theme.\n",
    "# Now, we calculate the Composite Risk Index (CRI) by averaging themes per day/location.\n",
    "\n",
    "df_cri = df_normalized.groupby(['date', 'location_id', 'location_name_english'])['normalized_risk'].mean().reset_index(name='composite_risk_index')\n",
    "\n",
    "print(\"Calculated Composite Risk Index (CRI).\")\n",
    "display(df_cri.head())\n",
    "print(\"-\" * 30, \"\\n\")\n",
    "\n",
    "\n",
    "# --- 6. Save the Final Time-Series Data ---\n",
    "print(\"--- Step 6: Saving Final Index Data ---\")\n",
    "OUTPUT_DIR = os.path.join(DATA_DIR, '04_feature')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Save the thematic and composite indices\n",
    "df_normalized.to_csv(os.path.join(OUTPUT_DIR, 'thematic_risk_indices.csv'), index=False)\n",
    "df_cri.to_csv(os.path.join(OUTPUT_DIR, 'composite_risk_index.csv'), index=False)\n",
    "\n",
    "print(f\"Final time-series data saved to: {OUTPUT_DIR}\")\n",
    "print(\"-\" * 30, \"\\n\")\n",
    "\n",
    "\n",
    "# --- 7. Example Visualization ---\n",
    "print(\"--- Step 7: Example Visualization ---\")\n",
    "# Let's visualize the CRI for a specific location, e.g., Baghdad\n",
    "location_to_plot = 'Baghdad'\n",
    "df_plot = df_cri[df_cri['location_name_english'] == location_to_plot]\n",
    "\n",
    "if not df_plot.empty:\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    \n",
    "    ax.plot(df_plot['date'], df_plot['composite_risk_index'], marker='o', linestyle='-', label='Composite Risk Index')\n",
    "    ax.set_title(f\"Daily Composite Risk Index for {location_to_plot}\", fontsize=16)\n",
    "    ax.set_ylabel(\"Risk Index (Normalized Score)\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"No data found for location: {location_to_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'folium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfolium\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfolium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MarkerCluster\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# --- 1. Load the Final Risk Index Data ---\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'folium'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import folium\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- 1. Load All Necessary Data ---\n",
    "print(\"--- Step 1: Loading Processed Data ---\")\n",
    "DATA_DIR = '../data'\n",
    "FEATURE_DIR = os.path.join(DATA_DIR, '04_feature')\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, '01_raw')\n",
    "\n",
    "# Load the risk index data\n",
    "df_cri = pd.read_csv(os.path.join(FEATURE_DIR, 'composite_risk_index.csv'))\n",
    "\n",
    "# Load the English location names dictionary\n",
    "with open(os.path.join(RAW_DATA_DIR, 'id_english_location_name.pkl'), 'rb') as f:\n",
    "    eng_locations = pickle.load(f)\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "print(\"-\" * 30, \"\\n\")\n",
    "\n",
    "\n",
    "# --- 2. Geocode All 357 Locations ---\n",
    "print(f\"--- Step 2: Geocoding All {len(eng_locations)} Locations ---\")\n",
    "# Initialize the geocoder (Nominatim is a free service from OpenStreetMap)\n",
    "geolocator = Nominatim(user_agent=\"food_crisis_mapper\")\n",
    "\n",
    "# RateLimiter prevents sending requests too fast, which can get you blocked\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "\n",
    "# Create a dictionary to store our results: {location_id: {'lat': lat, 'lon': lon}}\n",
    "location_coords = {}\n",
    "tqdm.pandas(desc=\"Geocoding Locations\")\n",
    "\n",
    "# We only need to geocode the primary English name for each location ID\n",
    "location_names_to_geocode = {loc_id: names[0] for loc_id, names in eng_locations.items()}\n",
    "\n",
    "for loc_id, name in tqdm(location_names_to_geocode.items(), desc=\"Fetching Coordinates\"):\n",
    "    try:\n",
    "        location = geocode(name)\n",
    "        if location:\n",
    "            location_coords[loc_id] = {'lat': location.latitude, 'lon': location.longitude}\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding '{name}': {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully geocoded {len(location_coords)} out of {len(eng_locations)} locations.\")\n",
    "print(\"-\" * 30, \"\\n\")\n",
    "\n",
    "\n",
    "# --- 3. Merge Coordinates and Aggregate Data ---\n",
    "print(\"--- Step 3: Merging Coordinates and Aggregating Risk Scores ---\")\n",
    "# Add lat/lon to the dataframe using the location_id\n",
    "df_cri['lat'] = df_cri['location_id'].map(lambda x: location_coords.get(x, {}).get('lat'))\n",
    "df_cri['lon'] = df_cri['location_id'].map(lambda x: location_coords.get(x, {}).get('lon'))\n",
    "\n",
    "# Drop rows where we couldn't find coordinates\n",
    "df_cri.dropna(subset=['lat', 'lon'], inplace=True)\n",
    "\n",
    "# Calculate the AVERAGE risk for each location over the whole period\n",
    "df_map_data = df_cri.groupby(['location_name_english', 'lat', 'lon'])['composite_risk_index'].mean().reset_index()\n",
    "\n",
    "# Normalize the risk index to a 0-1 scale\n",
    "df_map_data['normalized_risk'] = (df_map_data['composite_risk_index'] - df_map_data['composite_risk_index'].min()) / \\\n",
    "                                 (df_map_data['composite_risk_index'].max() - df_map_data['composite_risk_index'].min())\n",
    "\n",
    "print(\"Aggregated and normalized data for mapping:\")\n",
    "display(df_map_data.head())\n",
    "print(\"-\" * 30, \"\\n\")\n",
    "\n",
    "\n",
    "# --- 4. Create the Full Interactive Map ---\n",
    "print(\"--- Step 4: Generating the Full Interactive Map ---\")\n",
    "map_center = [33, 38]\n",
    "risk_map_full = folium.Map(location=map_center, zoom_start=5, tiles='CartoDB positron')\n",
    "\n",
    "for _, row in df_map_data.iterrows():\n",
    "    radius = 5 + (row['normalized_risk'] * 20)\n",
    "    \n",
    "    # Use a continuous color scale for better visualization\n",
    "    color = plt.cm.viridis(row['normalized_risk'])\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[row['lat'], row['lon']],\n",
    "        radius=radius,\n",
    "        color=f\"rgb({int(color[0]*255)}, {int(color[1]*255)}, {int(color[2]*255)})\",\n",
    "        fill=True,\n",
    "        fill_opacity=0.7,\n",
    "        popup=folium.Popup(f\"<b>{row['location_name_english']}</b><br>Avg. Risk Index: {row['composite_risk_index']:.6f}\", max_width=300)\n",
    "    ).add_to(risk_map_full)\n",
    "\n",
    "output_path_full = os.path.join(FEATURE_DIR, 'risk_hotspot_map_FULL.html')\n",
    "risk_map_full.save(output_path_full)\n",
    "\n",
    "print(f\"Full interactive map saved to: {output_path_full}\")\n",
    "print(\"You can open this HTML file in your browser.\")\n",
    "\n",
    "risk_map_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
