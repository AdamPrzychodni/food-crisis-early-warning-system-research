{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This notebook performs the foundational text processing for the main analysis. Its purpose is to take the raw, unstructured news articles and transform them into a clean, sentence-tokenized format that is ready for subsequent feature engineering and modeling.\n",
    "\n",
    "This foundational preprocessing pipeline consists of the following steps:\n",
    "\n",
    "1.  **Load Data**: Import the raw English and Arabic news articles.\n",
    "2.  **Clean Text**: Remove noise from the text, such as HTML tags, URLs, and extra whitespace.\n",
    "3.  **Tokenize Sentences**: Break down the cleaned text into individual sentences.\n",
    "4.  **Save Processed Data**: Store the clean, structured datasets for the next stage of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data\n",
    "\n",
    "First, let's load the two news article datasets from the previous EDA stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# --- Load the datasets ---\n",
    "DATA_DIR = '../data'\n",
    "df_eng = pd.read_csv(os.path.join(DATA_DIR, '01_raw/news-articles-eng.csv'))\n",
    "df_ara = pd.read_csv(os.path.join(DATA_DIR, '01_raw/news-articles-ara.csv'))\n",
    "\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. News Article Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning news articles...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete.\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans raw text by removing HTML tags, URLs, and normalizing whitespace.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "print(\"Cleaning news articles...\")\n",
    "df_eng['body_cleaned'] = df_eng['body'].apply(clean_text)\n",
    "df_ara['body_cleaned'] = df_ara['body'].apply(clean_text)\n",
    "print(\"Cleaning complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentence Tokenization\n",
    "\n",
    "We will use a regular expression to split the text into sentences. This method looks for common sentence-ending punctuation (. ! ?) followed by a space, which is a robust approach for news text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing English articles into sentences...\n",
      "Tokenizing Arabic articles into sentences...\n",
      "\n",
      "Sentence tokenization complete.\n",
      "\n",
      "--- Example of Regex Sentence Tokenization ---\n",
      "Article body has been split into 124 sentences.\n",
      "First 3 sentences:\n",
      "- Hussam al-Mahmoud | Yamen Moghrabi | Hassan Ibrahim On October 7, 2023, the world and the Middle East awoke to the drums of war beating in the Gaza Strip.\n",
      "- Over time, it turned into a reality that American efforts, Qatari and Egyptian mediation, condemnations, statements, summits, and conferences could not stop.\n",
      "- While Israel continues its war in the besieged Gaza Strip, attention is turning towards the potential outbreak of another war.\n"
     ]
    }
   ],
   "source": [
    "def regex_sent_tokenize(text):\n",
    "    \"\"\"\n",
    "    Splits text into sentences using a regular expression.\n",
    "    This is a dependency-free alternative to nltk.sent_tokenize.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return []\n",
    "    # Split on sentence-ending punctuation followed by a space or end of string\n",
    "    # The regex uses a \"positive lookbehind\" to keep the punctuation with the sentence.\n",
    "    sentences = re.split(r'(?<=[.!?۔])\\s+', text)\n",
    "    # Filter out any empty strings that might result from the split\n",
    "    return [s for s in sentences if s]\n",
    "\n",
    "# --- Apply the new, reliable tokenizer ---\n",
    "print(\"Tokenizing English articles into sentences...\")\n",
    "df_eng['sentences'] = df_eng['body_cleaned'].apply(regex_sent_tokenize)\n",
    "\n",
    "print(\"Tokenizing Arabic articles into sentences...\")\n",
    "df_ara['sentences'] = df_ara['body_cleaned'].apply(regex_sent_tokenize)\n",
    "\n",
    "print(\"\\nSentence tokenization complete.\")\n",
    "\n",
    "# --- Display a sample ---\n",
    "print(\"\\n--- Example of Regex Sentence Tokenization ---\")\n",
    "print(f\"Article body has been split into {len(df_eng['sentences'].iloc[0])} sentences.\")\n",
    "print(\"First 3 sentences:\")\n",
    "for sentence in df_eng['sentences'].iloc[0][:3]:\n",
    "    print(f\"- {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed and FILTERED English data saved to: ../data/02_processed/news_eng_processed.pkl\n",
      "Processed and FILTERED Arabic data saved to: ../data/02_processed/news_ara_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "PROCESSED_DATA_DIR = os.path.join(DATA_DIR, '02_processed')\n",
    "output_path_eng = os.path.join(PROCESSED_DATA_DIR, 'news_eng_processed.pkl')\n",
    "output_path_ara = os.path.join(PROCESSED_DATA_DIR, 'news_ara_processed.pkl')\n",
    "\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Save the smaller, filtered dataframes\n",
    "df_eng.to_pickle(output_path_eng)\n",
    "df_ara.to_pickle(output_path_ara)\n",
    "\n",
    "print(f\"\\nProcessed and FILTERED English data saved to: {output_path_eng}\")\n",
    "print(f\"Processed and FILTERED Arabic data saved to: {output_path_ara}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Additional Task: Completing the Risk Factor Data**\n",
    "\n",
    "Run this if you didn't run the EDA because in EDA we also translated.\n",
    "\n",
    "For good data governance and to aid future analysis, it's a best practice to have a complete dataset. The original `risk-factors.xlsx` file was missing the Arabic translations. A separate, one-time script was used to create a new file, `risk-factors-translated.xlsx`, which contains both the English and Arabic terms. This ensures our core data is complete and bilingual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping pre-translated Arabic risk factors...\n",
      "\n",
      "--- Translation Complete ---\n",
      "Sample of the updated DataFrame:\n",
      "  risk_factor_english risk_factor_arabic\n",
      "0  massive starvation        مجاعة هائلة\n",
      "1          rinderpest         طاعون بقري\n",
      "2     scanty rainfall         شح الأمطار\n",
      "3         dysfunction          خلل وظيفي\n",
      "4                rise             ارتفاع\n",
      "\n",
      "Successfully saved the complete, translated risk factors to: ../data/01_raw/risk-factors-translated.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Load your original risk factors file ---\n",
    "DATA_DIR = '../data'\n",
    "risk_factors_path = os.path.join(DATA_DIR, '01_raw/risk-factors.xlsx')\n",
    "df_risk = pd.read_excel(risk_factors_path)\n",
    "\n",
    "# --- 2. Use the pre-translated dictionary (fast and reliable) ---\n",
    "print(\"Mapping pre-translated Arabic risk factors...\")\n",
    "risk_factor_translations_ara = {\n",
    "    'massive starvation': 'مجاعة هائلة', 'rinderpest': 'طاعون بقري', 'scanty rainfall': 'شح الأمطار', 'dysfunction': 'خلل وظيفي', 'rise': 'ارتفاع', 'mass displacement': 'نزوح جماعي', 'conflict': 'صراع', 'hunger': 'جوع', 'malnutrition': 'سوء تغذية', 'drought': 'جفاف', 'locust': 'جراد', 'insecurity': 'انعدام الأمن', 'violence': 'عنف', 'poverty': 'فقر', 'displacement': 'نزوح', 'disease': 'مرض', 'death': 'موت', 'disaster': 'كارثة', 'crisis': 'أزمة', 'famine': 'مجاعة', 'emergency': 'طوارئ', 'shortage': 'نقص', 'cholera': 'كوليرا', 'malaria': 'ملاريا', 'measles': 'حصبة', 'typhoid': 'تيفوئيد', 'ebola': 'إيبولا', 'hiv': 'فيروس نقص المناعة البشرية', 'aids': 'الإيدز', 'tuberculosis': 'سل', 'diarrhea': 'إسهال', 'undernutrition': 'نقص التغذية', 'food prices': 'أسعار المواد الغذائية', 'inflation': 'تضخم', 'economic collapse': 'انهيار اقتصادي', 'currency devaluation': 'تخفيض قيمة العملة', 'unemployment': 'بطالة', 'corruption': 'فساد', 'sanctions': 'عقوبات', 'blockade': 'حصار', 'looting': 'نهب', 'theft': 'سرقة', 'crime': 'جريمة', 'terrorism': 'إرهاب', 'insurgency': 'تمرد', 'civil war': 'حرب أهلية', 'war': 'حرب', 'bombing': 'قصف', 'airstrike': 'غارة جوية', 'shelling': 'قصف مدفعي', 'gunfire': 'إطلاق نار', 'explosion': 'انفجار', 'massacre': 'مذبحة', 'genocide': 'إبادة جماعية', 'ethnic cleansing': 'تطهير عرقي', 'torture': 'تعذيب', 'rape': 'اغتصاب', 'abduction': 'اختطاف', 'kidnapping': 'خطف', 'hostage': 'رهينة', 'assassination': 'اغتيال', 'coup': 'انقلاب', 'political instability': 'عدم استقرار سياسي', 'protest': 'احتجاج', 'riot': 'شغب', 'curfew': 'حظر تجول', 'state of emergency': 'حالة طوارئ', 'martial law': 'أحكام عرفية', 'election violence': 'عنف انتخابي', 'border closure': 'إغلاق الحدود', 'refugee': 'لاجئ', 'asylum seeker': 'طالب لجوء', 'internally displaced person': 'نازح داخلي', 'migrant': 'مهاجر', 'human trafficking': 'اتجار بالبشر', 'smuggling': 'تهريب', 'flood': 'فيضان', 'hurricane': 'إعصار', 'cyclone': 'إعصار', 'typhoon': 'إعصار', 'earthquake': 'زلزال', 'tsunami': 'تسونامي', 'volcano': 'بركان', 'landslide': 'انهيار أرضي', 'avalanche': 'انهيار ثلجي', 'wildfire': 'حرائق غابات', 'heatwave': 'موجة حر', 'cold wave': 'موجة برد', 'hailstorm': 'عاصفة برد', 'tornado': 'إعصار', 'storm': 'عاصفة', 'monsoon': 'موسم الأمطار', 'crop failure': 'فشل المحاصيل', 'harvest failure': 'فشل الحصاد', 'livestock death': 'نفوق الماشية', 'water shortage': 'نقص المياه', 'power outage': 'انقطاع التيار الكهربائي', 'fuel shortage': 'نقص الوقود', 'road closure': 'إغلاق الطرق', 'infrastructure damage': 'أضرار في البنية التحتية', 'hospital closure': 'إغلاق المستشفيات', 'school closure': 'إغلاق المدارس', 'market closure': 'إغلاق الأسواق', 'aid shortage': 'نقص المساعدات', 'aid worker killed': 'مقتل عامل إغاثة', 'aid worker abducted': 'اختطاف عامل إغاثة', 'ngo withdrawal': 'انسحاب المنظمات غير الحكومية', 'un withdrawal': 'انسحاب الأمم المتحدة', 'peacekeeping mission': 'بعثة حفظ السلام', 'ceasefire violation': 'انتهاك وقف إطلاق النار', 'failed state': 'دولة فاشلة', 'anarchy': 'فوضى', 'armed group': 'جماعة مسلحة', 'militia': 'ميليشيا', 'rebel': 'متمرد', 'terrorist group': 'جماعة إرهابية', 'child soldier': 'جندي طفل', 'landmine': 'لغم أرضي', 'chemical weapon': 'سلاح كيماوي', 'biological weapon': 'سلاح بيولوجي', 'nuclear weapon': 'سلاح نووي', 'dirty bomb': 'قنبلة قذرة', 'small arms': 'أسلحة صغيرة', 'heavy weapons': 'أسلحة ثقيلة', 'artillery': 'مدفعية', 'tank': 'دبابة', 'fighter jet': 'طائرة مقاتلة', 'drone': 'طائرة بدون طيار', 'naval blockade': 'حصار بحري', 'piracy': 'قرصنة', 'human rights violation': 'انتهاك حقوق الإنسان', 'freedom of speech': 'حرية التعبير', 'freedom of press': 'حرية الصحافة', 'freedom of assembly': 'حرية التجمع', 'freedom of religion': 'حرية الدين', 'ethnic discrimination': 'تمييز عرقي', 'religious discrimination': 'تمييز ديني', 'gender discrimination': 'تمييز بين الجنسين', 'child labor': 'عمالة الأطفال', 'forced labor': 'العمل القسري', 'slavery': 'عبودية', 'debt bondage': 'عبودية الدين', 'land seizure': 'الاستيلاء على الأراضي', 'forced eviction': 'إخلاء قسري', 'land grab': 'الاستيلاء على الأراضي', 'brutal government': 'حكومة وحشية', 'bombing campaign': 'حملة قصف', 'transport bottleneck': 'عنق زجاجة في النقل', 'weather extremes': 'ظواهر جوية متطرفة', 'price rise': 'ارتفاع الأسعار', 'cattle plague': 'طاعون الماشية', 'mismanagement': 'سوء الإدارة', 'harvest decline': 'انخفاض المحصول', 'forests destroyed': 'تدمير الغابات', 'jihadist groups': 'جماعات جهادية', 'migration': 'هجرة', 'economic impoverishment': 'إفقار اقتصادي', 'continued strife': 'استمرار الصراع', 'ecological crisis': 'أزمة بيئية', 'slave trade': 'تجارة الرقيق', 'lack of agricultural infrastructure': 'نقص البنية التحتية الزراعية', 'stolen food aid': 'سرقة المساعدات الغذائية', 'gangs of bandits': 'عصابات قطاع الطرق', 'gastrointestinal': 'معدي معوي', 'hunger crises': 'أزمات الجوع', 'pests': 'آفات', 'clan battle': 'معركة عشائرية', 'regimes were toppled': 'إسقاط الأنظمة'\n",
    "}\n",
    "\n",
    "# Map the English keywords to their Arabic translations\n",
    "df_risk['risk_factor_arabic'] = df_risk['risk_factor_english'].map(risk_factor_translations_ara)\n",
    "\n",
    "print(\"\\n--- Translation Complete ---\")\n",
    "print(\"Sample of the updated DataFrame:\")\n",
    "print(df_risk.head())\n",
    "\n",
    "\n",
    "# --- 3. Save to a NEW file to preserve your original data ---\n",
    "output_filename = 'risk-factors-translated.xlsx'\n",
    "output_path = os.path.join(DATA_DIR, '01_raw', output_filename)\n",
    "\n",
    "df_risk.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"\\nSuccessfully saved the complete, translated risk factors to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
